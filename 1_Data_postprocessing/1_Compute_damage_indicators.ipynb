{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from damage_indicator_module.damage_indicator_module import*\n",
    "\n",
    "set_plot_formatting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT DATA OF THE BUILDING (manually uncomment desired building)\n",
    "\n",
    "# building_id = 'ID1008'\n",
    "# period = 0.95\n",
    "# n_stories = 4\n",
    "# n_floors_to_add = 1\n",
    "\n",
    "# building_id = 'ID1012' # 'ID1012_bad'  'ID1012_good'\n",
    "# period = 1.80\n",
    "# n_stories = 8\n",
    "# n_floors_to_add = 2\n",
    "\n",
    "# building_id = 'ID1014'\n",
    "# period = 2.15\n",
    "# n_stories = 12\n",
    "# n_floors_to_add = 3\n",
    "\n",
    "building_id = 'ID1021'\n",
    "period = 2.35\n",
    "n_stories = 20\n",
    "n_floors_to_add = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT MAINSHOCK-AFTERSHOCK ANALYSES CHARACTERISTICS\n",
    "n_gm = 44\n",
    "mainshock_scales = [0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_filename = '../0_Back_to_back_IDA_data/all_results_' + building_id + '.h5'\n",
    "\n",
    "# INPUT DATA FOR DAMAGE INDICATOR CALCULATIONS\n",
    "inspector_type = 'Probabilistic'\n",
    "# n_floors_to_add = 1; # floors to sum damage index around peak story drift\n",
    "                     # 4 story = 1, 8 story = 3, 12 story = 4, 20 story = 6\n",
    "\n",
    "# Design parameters of the buildings site\n",
    "Sms = 1.5*2/3\n",
    "Sm1 = 0.9*2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING ANALYSIS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometry and hinge capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(results_filename, 'r') as hf:\n",
    "    # Get hinge capacity    \n",
    "    building_group = '/building_metadata' \n",
    "    hinge_yield_rotation_positive = hf[building_group]['hinge_yield_rotation_positive'][:]\n",
    "    hinge_cap_rotation_positive = hf[building_group]['hinge_cap_rotation_positive'][:]\n",
    "    hinge_ultimate_rotation_positive = hf[building_group]['hinge_ultimate_rotation_positive'][:]\n",
    "    hinge_yield_rotation_negative = hf[building_group]['hinge_yield_rotation_negative'][:]\n",
    "    hinge_cap_rotation_negative = hf[building_group]['hinge_cap_rotation_negative'][:]\n",
    "    hinge_ultimate_rotation_negative = hf[building_group]['hinge_ultimate_rotation_negative'][:]\n",
    "    column_geometry = hf[building_group]['column_geometry'][:]\n",
    "    \n",
    "    key = '/intact_results/ida/collapse_intensities'\n",
    "    collapse_intensities = pd.read_hdf(results_filename, key)\n",
    "\n",
    "H_building = column_geometry[-1,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collapse fragility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scales = len(mainshock_scales) \n",
    "\n",
    "# Intact Collapse fragility\n",
    "key = 'intact_results/ida/collapse_fragilities'\n",
    "Savg_intact = pd.read_hdf(results_filename, key).loc['Sa_avg', 'Median']\n",
    "beta_Savg_intact = pd.read_hdf(results_filename, key).loc['Sa_avg', 'Beta']\n",
    "fragility_intact = pd.DataFrame({'Median': [Savg_intact], 'Beta': [beta_Savg_intact]})\n",
    "\n",
    "# Get the median collapse capacity and other DI\n",
    "j = 0\n",
    "Savg_med_col = np.zeros([n_gm*n_scales])\n",
    "beta_Savg_col = np.zeros([n_gm*n_scales])\n",
    "\n",
    "for gm_i in range(n_gm):\n",
    "    gm_id = 'GM'+str(gm_i+1) \n",
    "\n",
    "    for scale in mainshock_scales:\n",
    "        key = '/mainshock_damage_results/' + gm_id + '/' + str(scale) + 'Col/ida/collapse_fragilities'\n",
    "        colFragility = pd.read_hdf(results_filename, key)\n",
    "        Savg_med_col[j] = colFragility.Median.Sa_avg\n",
    "        beta_Savg_col[j] = colFragility.Beta.Sa_avg\n",
    "        j = j + 1\n",
    "\n",
    "# Create Dataframe with all collapse fragilities\n",
    "fragilities = pd.DataFrame(np.column_stack((Savg_med_col, beta_Savg_col)), \\\n",
    "                           columns = ['Median', 'Beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mainshock characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'ground_motion_records/gm_record_metadata'\n",
    "gm_metadata = pd.read_hdf(results_filename, key)\n",
    "\n",
    "Sa_avgCol = gm_metadata['Intact Collapse Sa_avg']\n",
    "Sa_Col = gm_metadata['Intact Collapse Sa(T1)']\n",
    "\n",
    "Sa_avgMain = np.zeros(n_gm*n_scales)\n",
    "Sa_Main = np.zeros(n_gm*n_scales)\n",
    "\n",
    "gm_name = []\n",
    "intensity_main = []\n",
    "\n",
    "j = 0\n",
    "for gm_i in range(n_gm):\n",
    "    for scale in mainshock_scales:\n",
    "        gm_name.append('GM' + str(gm_i))\n",
    "        intensity_main.append(str(scale) + 'Col')\n",
    "        Sa_avgMain[j] = Sa_avgCol[gm_i]*scale\n",
    "        Sa_Main[j] = Sa_Col[gm_i]*scale\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building design intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19083140217834815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2553191489361702"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_avg_design = design_sa_avg(period, Sms, Sm1)\n",
    "sa_design = design_spectra([period], Sms, Sm1)[0]\n",
    "\n",
    "sa_avg_design\n",
    "sa_design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPUTE DAMAGE INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM1\n",
      "0.2\n",
      "0.4\n",
      "0.5\n",
      "0.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4a727c448d65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# Get damage indicators based on floor damage index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             FDI[j,:], DI[j], DI_columns[j], DI_beams[j], columnBool[j] = compute_building_DI(peak_joint_pos,peak_joint_neg, hinge_yield_rotation_positive,\\\n\u001b[1;32m---> 58\u001b[1;33m                         hinge_cap_rotation_positive, hinge_yield_rotation_negative, hinge_cap_rotation_negative, inspector_type)\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mmax_FDI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFDI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box Sync\\FG PhD Thesis\\Papers\\Paper 1. PostEarthquake safety assessment\\Supplemental data\\damage_indicator_module\\damage_indicator_module\\damage_indicators.py\u001b[0m in \u001b[0;36mcompute_building_DI\u001b[1;34m(peak_joint_pos, peak_joint_neg, hinge_yield_rotation_positive, hinge_cap_rotation_positive, hinge_yield_rotation_negative, hinge_cap_rotation_negative, inspector_type)\u001b[0m\n\u001b[0;32m    269\u001b[0m                                                                        \u001b[0mhinge_yield_rotation_negative\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                                                                        \u001b[0mhinge_cap_rotation_negative\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                                                                        inspector_type)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;31m# Computes the building's damage index as sum of all Floor Damage Indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Box Sync\\FG PhD Thesis\\Papers\\Paper 1. PostEarthquake safety assessment\\Supplemental data\\damage_indicator_module\\damage_indicator_module\\damage_indicators.py\u001b[0m in \u001b[0;36mcompute_FDI\u001b[1;34m(floor_i, peak_joint_pos, peak_joint_neg, hinge_yield_rotation_positive, hinge_cap_rotation_positive, hinge_yield_rotation_negative, hinge_cap_rotation_negative, inspector_type)\u001b[0m\n\u001b[0;32m    211\u001b[0m                                                                                    capPos, yieldNeg, capNeg)\n\u001b[0;32m    212\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                         \u001b[0mpos_fragilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_FEMAP58_fragility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misBeam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapPos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                         \u001b[0mneg_fragilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_FEMAP58_fragility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misBeam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapNeg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                         floor_column_di[column_hinge_i], _ = compute_di_prob(peakPos, peakNeg, pos_fragilities,\n",
      "\u001b[1;32m~\\Box Sync\\FG PhD Thesis\\Papers\\Paper 1. PostEarthquake safety assessment\\Supplemental data\\damage_indicator_module\\damage_indicator_module\\damage_indicators.py\u001b[0m in \u001b[0;36mget_FEMAP58_fragility\u001b[1;34m(isBeam, rot_cap)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         fragilities = pd.DataFrame({'median': np.array([0.25, 0.55, 0.8]) * rot_cap,\n\u001b[1;32m---> 71\u001b[1;33m                                     'beta': np.array([1, 1, 1]) * 0.4}, index=[1, 2, 3])\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfragilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   5362\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5364\u001b[1;33m         \u001b[0mconverted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_index_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall_arrays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.clean_index_list\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get various Damage Indicators for each damage instance\n",
    "\n",
    "j = 0\n",
    "\n",
    "# Initialize arrays\n",
    "peak_story_drift = np.zeros([n_gm*n_scales,n_stories])\n",
    "residual_story_drift = np.zeros([n_gm*n_scales,n_stories])\n",
    "peak_drift_building = np.zeros([n_gm*n_scales]) \n",
    "residual_drift_building = np.zeros([n_gm*n_scales]) \n",
    "\n",
    "dsr_beams = np.zeros([n_gm*n_scales,4])\n",
    "dsr_columns = np.zeros([n_gm*n_scales,4])\n",
    "\n",
    "DI = np.zeros([n_gm*n_scales])\n",
    "max_FDI = np.zeros(n_gm*n_scales)\n",
    "FDI = np.zeros([n_gm*n_scales, n_stories+1])\n",
    "DI_sdr = np.zeros([n_gm*n_scales])\n",
    "DI_rsdr = np.zeros([n_gm*n_scales])\n",
    "DI_bottom = np.zeros([n_gm*n_scales])\n",
    "DI_bottom_sum = np.zeros([n_gm*n_scales])\n",
    "FDI_max_bottom = np.zeros([n_gm*n_scales])\n",
    "DI_columns = np.zeros([n_gm*n_scales])\n",
    "DI_beams = np.zeros([n_gm*n_scales])\n",
    "columnBool = np.zeros([n_gm*n_scales])\n",
    "\n",
    "Sa_avgMainRatio = np.zeros([n_gm*n_scales])\n",
    "Sa_MainRatio = np.zeros([n_gm*n_scales])\n",
    "\n",
    "for gm_i in range(n_gm):\n",
    "    gm_id = 'GM'+str(gm_i+1) \n",
    "    \n",
    "    print(gm_id)\n",
    "    \n",
    "    for scale in mainshock_scales:\n",
    "        print(scale)\n",
    "        with h5py.File(results_filename, 'r') as hf:\n",
    "    \n",
    "            damaged_gm_scale_group = '/mainshock_damage_results/' + gm_id + '/' + str(scale) + 'Col/mainshock_edp'\n",
    "                                   \n",
    "            # Get damage indicators based on drift\n",
    "            peak_story_drift[j, :] = hf[damaged_gm_scale_group]['peak_story_drift'][:]\n",
    "            residual_story_drift[j, :] = hf[damaged_gm_scale_group]['residual_story_drift'][:]                        \n",
    "            peak_drift_building[j] = max(abs(peak_story_drift[j]))\n",
    "            residual_drift_building[j] = max(abs(residual_story_drift[j]))\n",
    "                        \n",
    "            # Get damage indicators based on fraction of damaged components\n",
    "            building_group = '/mainshock_damage_results'\n",
    "            peak_joint_pos = hf[damaged_gm_scale_group]['peak_joint_rotations_pos']\n",
    "            peak_joint_neg = hf[damaged_gm_scale_group]['peak_joint_rotations_neg']            \n",
    "           \n",
    "            dsr_beams[j,:], dsr_columns[j,:] = get_dsr(peak_joint_pos, peak_joint_neg, hinge_yield_rotation_positive,\\\n",
    "                                             hinge_yield_rotation_negative, \\\n",
    "                                             hinge_cap_rotation_positive, \\\n",
    "                                             hinge_cap_rotation_negative, inspector_type)\n",
    "            \n",
    "            # Get damage indicators based on floor damage index      \n",
    "            FDI[j,:], DI[j], DI_columns[j], DI_beams[j], columnBool[j] = compute_building_DI(peak_joint_pos,peak_joint_neg, hinge_yield_rotation_positive,\\\n",
    "                        hinge_cap_rotation_positive, hinge_yield_rotation_negative, hinge_cap_rotation_negative, inspector_type)\n",
    "            max_FDI[j] = np.max(FDI[j,:])\n",
    "            \n",
    "            sdr_i = abs(peak_story_drift[j, :])\n",
    "            fdi_i = FDI[j, :]\n",
    "            indeces = sdr_i.argsort()\n",
    "            DI_sdr[j] = sum_fdi_at_peak(indeces[-1], fdi_i, n_floors_to_add)\n",
    "            \n",
    "            rsdr_i = abs(residual_story_drift[j, :])\n",
    "            indeces = rsdr_i.argsort()\n",
    "            DI_rsdr[j] = sum_fdi_at_peak(indeces[-1], fdi_i, n_floors_to_add)\n",
    "                        \n",
    "            DI_bottom[j] = sum(fdi_i[1:n_floors_to_add+1])/n_floors_to_add\n",
    "            \n",
    "            DI_bottom_sum[j] = sum(fdi_i[1:n_floors_to_add+1])\n",
    "            \n",
    "            FDI_max_bottom[j] = max(fdi_i[1:n_floors_to_add+1])\n",
    "            \n",
    "            # Get intensity based damage indicators\n",
    "            Sa_avgMainRatio[j] =  Sa_avgMain[j]/sa_avg_design\n",
    "            Sa_MainRatio[j] =  Sa_Main[j]/sa_design\n",
    "            \n",
    "            j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDUCTION IN COLLAPSE CAPACITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduction in median collapse capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = Savg_med_col/Savg_intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15873920814294465\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(min(k))\n",
    "print(np.argwhere(k < 0.1))\n",
    "\n",
    "index_delete = np.argwhere(k < 0.1)\n",
    "k[index_delete] = 0.1\n",
    "\n",
    "# a = np.arange(start=0, stop=308, step=7)\n",
    "# k2 = np.delete(k,a)\n",
    "# k2.shape\n",
    "# k[a]\n",
    "# index_delete = np.argwhere(k2>1)\n",
    "# k[index_delete].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE DAMAGE INDICATOR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['GM main', 'Scale main', 'FDI', 'dsr_beams', 'dsr_columns', 'peak_story_drift', 'residual_story_drift']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "column_names = ['GM main', 'Scale main', 'Sa_avgMain', 'Sa_Main', 'Savg_med_col', 'beta_Savg_col', '$\\kappa$', \n",
    "                '$SDR_{peak}$', '$RSDR_{peak}$', 'FDI', '$FDI_{peak}$', 'DI hinges', '$DI_{sdr}$', '$DI_{bottom}$', \n",
    "                '$DI_{bottom}^{sum}$','$FDI_{max}^{bottom}$','dsr_beams', 'dsr_columns', 'column_damage?', \n",
    "                'peak_story_drift', 'residual_story_drift', \n",
    "                '$Sa(T_1)_{avg}^{mainshock}/Sa(T_1)_{avg}^{DBE}$', '$Sa(T_1)^{mainshock}/Sa(T_1)^{DBE}$']\n",
    "\n",
    "damage_instance_results = pd.DataFrame(list(zip(gm_name, intensity_main, Sa_avgMain, Sa_Main, Savg_med_col, \n",
    "                                                beta_Savg_col, k, peak_drift_building, residual_drift_building, \n",
    "                                                FDI, max_FDI, DI, DI_sdr, DI_bottom, DI_bottom_sum, FDI_max_bottom, \n",
    "                                                dsr_beams, dsr_columns, columnBool, \n",
    "                                                peak_story_drift, residual_story_drift, Sa_avgMainRatio, \n",
    "                                                Sa_MainRatio)), columns=column_names)\n",
    "\n",
    "# UNCOMMENT THE APPROPIATE FILENAME\n",
    "damage_instance_results.to_hdf('Damage_Instances_per_building.h5', key=building_id)\n",
    "# damage_instance_results.to_hdf('Damage_Instances_' + building_id[0:6] + '_mat_props.h5', key=building_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
